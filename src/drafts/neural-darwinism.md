+++
title = "Neural Darwinism"
slug = "neural-darwinism"
date = "2020-1-2"
+++

I'm starting my work as a graduate researcher tomorrow I'm very excited to start so I thought I'd open with a little intro into what we're going to be working on.

Our research is going to be tackling the generalization part of artificial general intelligence. That is, how do we build machine learning models that can handle millions of tasks and generalize to new tasks it may have never seen?

We are approaching this problem with inspiration from neural networks, evolutionary algorithms, and a large scale theory of brain function called neural darwinism.



The project is inspired by a large scale theory of brain function called neural darwinism, which says that the structure and strength of connections between neurons in the brain develop as the result of selectionist processes.



We are working to apply this idea to artificial neural networks. 



How can we build machine learning systems that can handle millions of tasks, and that can learn to successfully accomplish new tasks automatically? Currently, weâ€™re mostly training separate machine models for each new task, starting from scratch, or at best, from a model trained on one or a few highly related tasks. As such, the models we train are really good at one or a few things, but not good at anything else. However, what we truly want are models that are good at leveraging their expertise at doing many things, so that they are able to learn to do a new thing with relatively little training data and computation. This is a true grand challenge which will require expertise and advances in many areas spanning solid-state circuit design, computer architecture, ML-focused compilers, distributed systems, machine learning algorithms and domain experts across many other fields in order to build systems that can generalize to solve new tasks independently across a full range of application areas.